\chapter[Finite elements for parabolic problems]{Finite elements for \\
parabolic problems in 1D}

We now consider a more general parabolic PDE with mixed boundary conditions,
\begin{equation}\label{eq: parabolic ivp 1d}
\begin{aligned}
u_t+\mathcal{L}u&=f(x,t)&&\text{for $0<x<L$ and $0<t<T$,}\\
u&=\gamma_0(t)&&\text{at $x=0$, for $0<t<T$,}\\
au'&=\gamma_L(t)&&\text{at $x=L$, for $0<t<T$,}\\
u&=u_0(x)&&\text{for $0<x<L$ when $t=0$,}
\end{aligned}
\end{equation}
where $\mathcal{L}u=-\bigl(a(x)u'\bigr)'+c(x)u$ as before 
in~\eqref{eq: L self-adjoint}.  The identity~\eqref{eq: Lu v by parts} implies 
that, for any test function~$v(x)$,
\begin{equation}\label{eq: parabolic 1d weak}
\int_0^Lu_tv\,dx+\int_0^L\bigl(a(x)u_xv_x+c(x)uv\bigr)\,dx
	=\gamma_L(t)v(L)+\int_0^Lf(x,t)v\,dx
\quad\text{provided $v(0)=0$.}
\end{equation}
We will use this relation to formulate a semidiscrete finite element 
solution~$u_h(x,t)\approx u(x,t)$ and then apply finite difference 
approximations in time to derive some fully-discrete schemes.

\section{Semidiscrete method}\label{sec: semidiscrete parabolic FEM}
Let $V_h$ denote the space of continuous, piecewise-linear functions for a 
given mesh~\eqref{eq: 1d nodes} on the spatial interval~$[0,L]$.  We define the 
solution set (now dependent on~$t$) and test space by
\[
S_h(t)=\{\,v\in V_h:v(0)=\gamma_0(t)\,\}
\quad\text{and}\quad
T_h=\{\,v\in V_h:v(0)=0\,\}.
\]
We also choose $u_{0h}\in V_h$ such that $u_0\approx u_{0h}$; the simplest 
choice would be the interpolant $u_{0h}=\mathcal{Q}_1u_0$. The semidiscrete
finite element solution~$u_h(x,t)$ is then defined for~$0\le t\le T$ by 
requiring that $u_h(\cdot,t)\in S_h(t)$ and
\begin{equation}\label{eq: semidiscrete fem 1d}
\int_0^L(u_h)_tv\,dx+\int_0^L\bigl(a(x)(u_h)_xv_x+c(x)u_hv\bigr)\,dx
    =\gamma_L(t)v(L)+\int_0^Lf(x,t)v\,dx
\quad\text{for all $v\in T_h$,}
\end{equation}
with $u_h(0)=u_{0h}$. The stiffness matrix~$\boldsymbol{A}$ and mass 
matrix~$\boldsymbol{C}$ are the same as in the stationary problem 
(section~\ref{sec: self-adjoint 1d}), but the nodal 
values of the solution are now time-dependent, with
\[
u_h(x,t)=\sum_{q=0}^P U_q(t)\chi_q(x)\quad\text{for $0\le x\le L$,}\quad
\text{where $U_q(t)=u_h(x_q,t)$.}
\]
Likewise, the load vector is time-dependent in general, since 
\[
f_p(t)=\int_0^Lf(x,t)\chi_p(x)\,dx.
\]
Noting 
\[
\int_0^L(u_h)_t\chi_p\,dx=\int_0^L\sum_{q=0}^P
    \frac{dU_q}{dt}\,\chi_q(x)\chi_p(x)\,dx=\sum_{q=0}^P m_{pq}\,\frac{dU_q}{dt}
    \quad\text{where $m_{pq}=\int_0^L\chi_q\chi_p\,dx$,}
\]
we see by choosing $v=\chi_p$ in~\eqref{eq: semidiscrete fem 1d} that
\[
\sum_{q=0}^P\biggl(m_{pq}\,\frac{dU_q}{dt}+a_{pq}U_q+c_{pq}U_q\biggr)
    =\gamma_L(t)\chi_p(L)+f_p(t),
\]
with $U_q(0)=u_{0h}(x_q)$.  Since $U_0(t)=u_h(x_0,t)=\gamma_0(t)$,
\[
\sum_{q=1}^P\biggl(m_{pq}\,\frac{dU_q}{dt}+a_{pq}U_k+c_{pq}U_q\biggr)
    =f_p(t)+g_p(t)
\]
where
\[
g_p(t)=\gamma_L(t)\delta_{pP}-m_{p0}\gamma_0'(t)-(a_{p0}+c_{p0})\gamma_0(t),
\]
and so the nodal values satisfy the $P\times P$ system of linear ODEs,
\begin{equation}\label{eq: semidiscrete fem 1d ODE}
\boldsymbol{M}\,\frac{d\boldsymbol{U}}{dt}
+(\boldsymbol{A}+\boldsymbol{C})\boldsymbol{U}=\boldsymbol{f}(t)
    +\boldsymbol{g}(t)\quad\text{for $0\le t\le T$,}
    \quad\text{with $\boldsymbol{U}(0)=\boldsymbol{U}_0$,}
\end{equation}
where 
\[
\boldsymbol{M}=[m_{pq}]_{p,q=1}^P,\qquad 
\boldsymbol{A}=[a_{pq}]_{p,q=1}^P,\qquad
\boldsymbol{C}=[c_{pq}]_{p,q=1}^P,
\]
and
\[
\boldsymbol{f}(t)=[f_p(t)]_{p=1}^P,\qquad
\boldsymbol{g}(t)=[g_p(t)]_{p=1}^P,\qquad
\boldsymbol{U}_0=[u_{0h}(x_p)]_{p=1}^P.
\]
By using an energy argument, we can show that $u_h$ is stable.

\begin{theorem}
Assume that $c(x)\ge0$.  Then, the semidiscrete finite element 
method~\eqref{eq: semidiscrete fem 1d} has a unique 
solution~$u_h(\cdot,t)\in S_h(t)$ for~$0\le t\le T$.  Furthermore, the
method is stable in the sense that
\[
\|(u_h-\eta)(\cdot,t)\|\le\|(u-\eta)(\cdot,0)\|
	+2\int_0^t\|(f-\eta_s-\mathcal{L}\eta)(\cdot,s)\|\,ds
	\quad\text{for $0\le t\le T$,}
\]
where $\eta$ is any function satisfying
\[
\eta(\cdot,t)\in S_h(t),\qquad \eta(0,t)=\gamma_0(t),\qquad
	a(L)\eta_x(L,t)=\gamma_L(t).
\]  
For example, we my choose
\[
\eta(x,t)=\gamma_0(t)+\frac{\gamma_L(t)}{a(L)}\,x.
\]
\end{theorem}
\begin{proof}
The existence and uniqueness of $u_h$ follows from a standard result for
systems of ODEs.  To establish the stability estimate, we first
use the energy inner product~\eqref{eq: energy iprod} to write
\eqref{eq: semidiscrete fem 1d} as
\[
\iprod{(u_h)_t,v}+\iprod{u_h,v}_{\mathcal{L}}=\gamma_L(t)v(L)
	+\iprod{f(\cdot,t),v}\quad\text{for all $v\in T_h$.}
\]
Thus, the difference 
\[
w(x,t)=u_h(x,t)-\eta(x,t)
\]
satisfies 
\[
w(\cdot,t)\in S_h(t)\quad\text{and}\quad
w(0,t)=u_h(0,t)-\gamma_0(t)=0,
\]
implying that $w(\cdot,t)\in T_h$ for each~$t\in[0,T]$, and we see by
choosing $v(x)=w(x,t)$ that
\[
\iprod{(u_h)_t,w(\cdot,t)}+\iprod{u_h,w(\cdot,t)}_{\mathcal{L}}
	=\gamma_L(t)w(L,t)+\iprod{f(\cdot,t),w(\cdot,t)}.
\]
Since $u_h=w+\eta$,
\[
\iprod{w_t+\eta_t,w}+\iprod{w+\eta,w}_{\mathcal{L}}
	=\gamma_L(t)w(L,t)+\iprod{f,w},
\]
and integration by parts gives
\[
\iprod{\eta,w}_{\mathcal{L}}=[a\eta_xw]_0^L+\iprod{\mathcal{L}\eta,w}
	=\gamma_L(t)w(L,t)+\iprod{\mathcal{L}\eta,w}.
\]
Therefore,
\[
\iprod{w_t,w}+\|w\|_{\mathcal{L}}^2=\iprod{g,w}
\quad\text{where}\quad g(x,t)=f(x,t)-\eta_t(x,t)-(\mathcal{L}\eta)(x,t).
\]
Observe that
\[
\iprod{w_t,w}=\frac{1}{2}\,\frac{d}{dt}\|w(\cdot,t)\|^2,
\]
so after integrating in time to arrive at the estimate
\[
\|w(\cdot,t)\|^2+2\int_0^t\|w(\cdot,s)\|_{\mathcal{L}}^2\,ds
\le\|w_0\|^2+2\int_0^t\iprod{g(\cdot,s),w(\cdot,s)}\,ds
\quad\text{for $0\le t\le T$,}
\]
where 
\[
w_0(x)=w(x,0)=(u-\eta)(x,0).
\]
Since $\|w(\cdot,t)\|$ is a continuous function of~$t$, there is a 
$t^*\in[0,t]$ such that 
\[
\|w(\cdot,t^*)\|=\max_{0\le s\le t}\|w(\cdot,s)\|. 
\]
Therefore, using the Cauchy--Schwarz inequality,
\begin{multline*}
\|w(\cdot,t)\|^2\le\|w(\cdot,t)\|^2+2\int_0^t\|w(\cdot,s)\|_{\mathcal{L}}^2\,ds
\le\|w(\cdot,t^*)\|^2+2\int_0^{t^*}\|w(\cdot,s)\|_{\mathcal{L}}^2\,ds\\
\le\|w_0\|^2+2\int_0^{t^*}\|g(\cdot,s)\|\|w(\cdot,s)\|\,ds
\le\|w(\cdot,t^*)\|\biggl(\|w_0\|+2\int_0^t\|g(\cdot,s)\|\,ds\biggr),
\end{multline*}
so
\[
\|w(\cdot,t)\|\le\|w_0\|+2\int_0^t\|g(\cdot,s)\|\,ds,
\]
which gives the desired estimate.
\end{proof}
\begin{corollary}
\begin{multline*}
\|u_h(\cdot,t)\|\le\|u_{0h}\|+2\int_0^t\|f(\cdot,s)\|\,ds\\
	+C\biggl(|\gamma_0(t)|+|\gamma_L(t)|
	+\int_0^t\bigl(|\gamma_0(s)|+|\gamma_0'(s)|
	+|\gamma_L(s)|+|\gamma_L'(s)|\bigr)\,ds\biggr).
\end{multline*}
\end{corollary}

\section{Time stepping}\label{sec: time stepping}
We can use finite differences for the time integration, putting
\begin{equation}\label{eq: uniform tn}
t_n=n\,\Delta t\quad\text{for $0\le n\le N$,}
    \quad\text{where $\Delta t=\frac{T}{N}$,}
\end{equation}
and seeking $U^n_p\approx u_h(x_p,t_n)\approx u(x_p,t_n)$.

\begin{example}
The \emph{forward Euler method} based on~\eqref{eq: semidiscrete fem 1d ODE} is
\[
\boldsymbol{M}\,\frac{\boldsymbol{U}^{n+1}-\boldsymbol{U}^n}{\Delta t}
+(\boldsymbol{A}+\boldsymbol{C})\boldsymbol{U}^n=\boldsymbol{f}^n
    +\boldsymbol{g}^n\quad\text{for $0\le n\le N-1$,}
    \quad\text{with $\boldsymbol{U}^0=\boldsymbol{U}_0$,}
\]
where $\boldsymbol{U}^n=[U^n_p]_{p=1}^P$, 
$\boldsymbol{f}^n=\boldsymbol{f}(t_n)$~and 
$\boldsymbol{g}^n=\boldsymbol{g}(t_n)$.  Notice that this method is not 
actually explicit, due to the presence of the matrix~$\boldsymbol{M}$: at the 
$n$th time step we have to solve the linear system
\[
\boldsymbol{M}\boldsymbol{U}^{n+1}=\bigl(\boldsymbol{M}
-\Delta t\,(\boldsymbol{A}+\boldsymbol{C})\bigr)\boldsymbol{U}^n
    +\Delta t\,\bigl(\boldsymbol{f}^n+\boldsymbol{g}^n\bigr).
\]
\end{example}

\begin{example}
The \emph{backward Euler method} based on~\eqref{eq: semidiscrete fem 1d ODE} is
\[
\boldsymbol{M}\,\frac{\boldsymbol{U}^{n}-\boldsymbol{U}^{n-1}}{\Delta t}
+(\boldsymbol{A}+\boldsymbol{C})\boldsymbol{U}^n=\boldsymbol{f}^n
    +\boldsymbol{g}^n\quad\text{for $1\le n\le N$,}
    \quad\text{with $\boldsymbol{U}^0=\boldsymbol{U}_0$,}
\]
which requires that we solve the linear systems
\[
\bigl(\boldsymbol{M}+\Delta t\,(\boldsymbol{A}+\boldsymbol{C})\bigr) 
    \boldsymbol{U}^n=\boldsymbol{M}\boldsymbol{U}^{n-1}
    +\Delta t\,\bigl(\boldsymbol{f}^n+\boldsymbol{g}^n\bigr).
\]
\end{example}

\begin{example}
The \emph{Crank--Nicolson method} based on~\eqref{eq: semidiscrete fem 1d ODE} 
is
\[
\boldsymbol{M}\,\frac{\boldsymbol{U}^{n}-\boldsymbol{U}^{n-1}}{\Delta t}
+(\boldsymbol{A}+\boldsymbol{C})\boldsymbol{U}^{n-1/2}=\boldsymbol{f}^{n-1/2}
    +\boldsymbol{g}^{n-1/2}\quad\text{for $1\le n\le N$,}
    \quad\text{with $\boldsymbol{U}^0=\boldsymbol{U}_0$,}
\]
which requires that we solve the linear systems
\[
\bigl(\boldsymbol{M}+\tfrac12\Delta t\,(\boldsymbol{A}+\boldsymbol{C})\bigr) 
    \boldsymbol{U}^n
=\bigl(\boldsymbol{M}-\tfrac12\Delta t\,(\boldsymbol{A}+\boldsymbol{C})\bigr) 
    \boldsymbol{U}^{n-1}
    +\Delta t\,\bigl(\boldsymbol{f}^{n-1/2}+\boldsymbol{g}^{n-1/2}\bigr).
\]
\end{example}

\section{Discrete separation of variables}\label{sec: discrete separation}
Consider the special case when $f(x,t)\equiv0$, $\gamma_0(t)\equiv0$~and 
$\gamma_L(t)\equiv0$.  Let $(\phi_k,\lambda_k)$ be the $k$th eigenpair for the 
operator $\mathcal{L}$, so that
\[
\mathcal{L}\phi_k=\lambda_k\phi_k\quad\text{for $0<x<L$,}\quad
\text{with $\phi_k(0)=0=a\phi_k'(L)$.}
\]
For the special choice of initial condition
\[
u_0(x)=\phi_k(x),
\]
the solution of the continuous problem $u_t+\mathcal{L}u=0$ is simply
\begin{equation}\label{eq: u0 eigenfunction}
u(x,t)=e^{-\lambda_kt}\phi_k(x).
\end{equation}
We shall assume that $c(x)\ge0$ for $0<x<L$, which ensures that $\lambda_k>0$ 
for all~$k$; see exercise~\ref{ex: quadratic form}.  Thus, the 
factor~$e^{-\lambda_kt}$ decreases monotonically to zero as~$t\to\infty$.

Each of the matrices $\boldsymbol{A}$, $\boldsymbol{C}$~and $\boldsymbol{M}$ is 
real and symmetric, and in addition $\boldsymbol{M}$ is positive-definite, so 
there exist \emph{generalised eigenpairs} $(\boldsymbol{\Phi}_k,\Lambda_k)$ 
such that 
\[
(\boldsymbol{A}+\boldsymbol{C})\boldsymbol{\Phi}_k
    =\Lambda_k\boldsymbol{M}\boldsymbol{\Phi}_k,\qquad
\boldsymbol{\Phi}_j^T(\boldsymbol{A}+\boldsymbol{C})\boldsymbol{\Phi}_k
    =\Lambda_k\delta_{jk},\qquad
\boldsymbol{\Phi}_j^T\boldsymbol{M}\boldsymbol{\Phi}_k=\delta_{jk}
\]
for $j$, $k\in\{1,2,\ldots,P\}$.  Our assumptions ensure that 
$\boldsymbol{A}+\boldsymbol{C}$ is positive-definite, so $\Lambda_k>0$ 
for~$1\le k\le2P$.

Suppose we choose discrete initial data
\[
\boldsymbol{U}_0=\boldsymbol{\Phi}_k.
\]
For moderate values of~$k$, we expect 
$\boldsymbol{\Phi_k}\approx[\phi_k(x_p)]_{p=1}^P$, assuming we label the 
$\lambda_k$~and $\Lambda_k$ so that
\[
0<\lambda_1\le\lambda_2\le\lambda_3\le\cdots
\quad\text{and}\quad
0<\Lambda_1\le\Lambda_2\le\cdots\le\Lambda_P,
\]
and make appropriate choices for the corresponding eigenfunctions and 
eigenvectors. In our special case, the semidiscrete initial-value 
problem~\eqref{eq: semidiscrete fem 1d ODE} simplifies to
\[
\boldsymbol{M}\,\frac{d\boldsymbol{U}}{dt}
+(\boldsymbol{A}+\boldsymbol{C})\boldsymbol{U}=\boldsymbol{0}
    \quad\text{for $0\le t\le T$,}
    \quad\text{with $\boldsymbol{U}(0)=\boldsymbol{\Phi}_k$,}
\]
which has the solution
\begin{equation}
\boldsymbol{U}(t)=e^{-\Lambda_kt}\boldsymbol{\Phi}_k,
\end{equation}
which again decreases monotonically to zero as~$t\to\infty$.

Let us compare theses continuous-time solutions with the discrete-time 
solutions for the three time-stepping schemes described in 
section~\ref{sec: time stepping}.  

\begin{example}
The forward Euler method in this special case is
\[
\boldsymbol{M}\boldsymbol{U}^{n+1}=\bigl(\boldsymbol{M}
-\Delta t\,(\boldsymbol{A}+\boldsymbol{C})\bigr)\boldsymbol{U}^n,
\]
and since
\[
\bigl(\boldsymbol{M} 
-\Delta t\,(\boldsymbol{A}+\boldsymbol{C})\bigr)\boldsymbol{\Phi}_k
    =\boldsymbol{M}\Phi_k-\Delta t\,\Lambda_k\boldsymbol{M}\boldsymbol{\Phi}_k
    =\boldsymbol{M}(1-\Delta t\,\Lambda_k)\boldsymbol{\Phi}_k
\]
we see by induction on $n$ that
\[
\boldsymbol{U}^n=(1-\Delta t\,\Lambda_k)^n\boldsymbol{\Phi}_k.
\]
If $\Delta t\,\Lambda_k<1$ then the factor~$(1-\Delta t\,\Lambda_k)^n$ 
decreases monotonically to zero as~$t_n\to\infty$, so we have the correct 
qualitative behaviour of the solution, and furthermore
\[
e^{-\Lambda_kt_n}=e^{-\Lambda_k n\,\Delta t}
    =\bigl(e^{-\Delta t\Lambda_k}\bigr)^n\approx(1-\Delta t\,\Lambda_k)^n
    \quad\text{if $\Delta t\,\Lambda_k$ is small, for $n$ fixed.}
\]
If $1<\Delta t\,\Lambda_k<2$ then $(1-\Delta t\,\Lambda_k)^n$ tends to zero, 
but with an oscillating sign, as $t_n\to\infty$, which is the wrong qualitative 
behaviour. If $\Delta t\,\Lambda_k>2$, then $(1-\Delta t\,\Lambda_k)^n$ not 
only oscillates but is also unbounded.
\end{example}

\begin{example}
The \emph{backward Euler method} in this special case is
\[
\bigl(\boldsymbol{M}+\Delta t\,(\boldsymbol{A}+\boldsymbol{C})\bigr) 
    \boldsymbol{U}^n=\boldsymbol{M}\boldsymbol{U}^{n-1},
\]
and since
\[
\bigl(\boldsymbol{M} +\Delta t\,(\boldsymbol{A}+\boldsymbol{C})\bigr)^{-1}
\boldsymbol{M}\boldsymbol{\Phi}_k
    =(1+\Delta t\,\Lambda_k)^{-1}\boldsymbol{\Phi_k}
\]
we see by induction on $n$ that
\[
\boldsymbol{U}^n=(1+\Delta t\,\Lambda_k)^{-n}\boldsymbol{\Phi}_k.
\]
The factor~$(1+\Delta t\,\Lambda_k)^{-n}$ always decreases monotonically to 
zero as~$t_n\to\infty$, so we have the correct qualitative behaviour no matter 
how large $\Delta t$.  Furthermore,
\[
e^{-\Lambda_kt_n}=\bigl(e^{-\Delta t\Lambda_k}\bigr)^n
    \approx(1+\Delta t\,\Lambda_k)^{-n}
    \quad\text{if $\Delta t\,\Lambda_k$ is small, for $n$ fixed.}
\]
\end{example}

\begin{example}
The \emph{Crank--Nicolson method} in this special case is
\[
\bigl(\boldsymbol{M}+\tfrac12\Delta t\,(\boldsymbol{A}+\boldsymbol{C})\bigr) 
    \boldsymbol{U}^n
=\bigl(\boldsymbol{M}-\tfrac12\Delta t\,(\boldsymbol{A}+\boldsymbol{C})\bigr) 
    \boldsymbol{U}^{n-1},
\]
and since
\[
\bigl(\boldsymbol{M}+\tfrac12\Delta t\,
    (\boldsymbol{A}+\boldsymbol{C})\bigr)^{-1}
\bigl(\boldsymbol{M}-\tfrac12\Delta t\,(\boldsymbol{A}+\boldsymbol{C})\bigr) 
    \boldsymbol{\Phi_k}
    =\frac{(1-\tfrac12\Delta t\,\Lambda_k)^{-1}}%
{(1+\tfrac12\Delta t\,\Lambda_k)^{-1}}\,\boldsymbol{\Phi_k},
\]
we see by induction on $n$ that
\[
\boldsymbol{U}^n=\biggl(
    \frac{1-\tfrac12\Delta t\,\Lambda_k}{1+\tfrac12\Delta t\,\Lambda_k}\biggr)^n
    \boldsymbol{\Phi}_k.
\]
Thus, the correct qualitative behaviour occurs when $\Delta t\,\Lambda_k<2$.
If $\Delta t\,\Lambda_k>2$, then $\boldsymbol{U}^n$ still tends to zero 
as~$t_n\to\infty$, but with a sign oscillation.  Also, rate of decay becomes 
slower and slower with increasing values of~$\Delta t\,\Lambda_k$.
\end{example}

For general initial data~$u_0$, we know from section~\ref{sec: separation} 
that the continuous solution is
\[
u(x,t)=e^{-t\mathcal{L}}u_0(x)
    =\sum_{k=1}^\infty\widehat{(u_0)}_k e^{-\lambda_kt}\phi_k(x)
\quad\text{where}\quad
\widehat{(u_0)}_k=\frac{\langle u_0,\phi_k\rangle}{\|\phi_k\|^2}.
\]
Similarly, we claim that for a general discrete
data~$\boldsymbol{U}_0$, the semidiscrete finite element solution has the form
\begin{equation}\label{eq: semidiscrete FEM Fourier}
\boldsymbol{U}(t)=e^{-t\boldsymbol{M}^{-1}(\boldsymbol{A}+\boldsymbol{C})}
    \boldsymbol{U}_0
    =\sum_{k=1}^P\widehat{(\boldsymbol{U}_0)}_k e^{-\Lambda_kt}
    \boldsymbol{\Phi}_k
\quad\text{where}\quad
\widehat{(\boldsymbol{U}_0)}_k
=\frac{\langle\boldsymbol{U}_0,\boldsymbol{\Phi}_k\rangle_{\boldsymbol{M}}}%
{\|\boldsymbol{\Phi_k}\|_{\boldsymbol{M}}^2}.
\end{equation}
Here, $\langle\boldsymbol{V},\boldsymbol{W}\rangle_{\boldsymbol{M}}
=\boldsymbol{V}^T\boldsymbol{M}\boldsymbol{W}$ and 
$\|\boldsymbol{V}\|_{\boldsymbol{M}}
=\sqrt{\boldsymbol{V}^T\boldsymbol{M}\boldsymbol{V}}$ are the inner product and 
norm induced by the positive-definite matrix~$\boldsymbol{M}$.  Indeed, 
$\boldsymbol{U}(t)=e^{-t\boldsymbol{M}^{-1}(\boldsymbol{A}+\boldsymbol{C})}
\boldsymbol{U}_0$ because
\[
\frac{d\boldsymbol{U}}{dt}+\boldsymbol{M}^{-1}(\boldsymbol{A}+\boldsymbol{C})
\boldsymbol{U}=\boldmath{0},
\]
and we have
\[
\boldsymbol{U}_0=\sum_{k=1}^P\widehat{(\boldsymbol{U}_0)}_k\boldsymbol{\Phi}_k,
\]
because the eigenvectors~$\boldsymbol{\Phi}_k$ form an 
$\boldsymbol{M}$-orthogonal basis for~$\mathbb{R}^P$.  The 
representation~\eqref{eq: semidiscrete FEM Fourier} then follows because
$\boldsymbol{M}^{-1}(\boldsymbol{A}+\boldsymbol{C})\boldsymbol{\Phi}_k
=\Lambda_k\boldsymbol{\Phi}_k$.

\begin{example}\label{example: forward Euler FEM}
For general discrete initial data~$\boldsymbol{U}_0$, the forward Euler method 
gives
\[
\boldsymbol{U}^n=\sum_{k=1}^P\widehat{(\boldsymbol{U}_0)}_k 
    (1-\Delta t\,\Lambda_k)^n\Phi_k,
\]
and therefore
\[
\|\boldsymbol{U}^n\|_{\boldsymbol{M}}^2
    =\sum_{k=1}^P\bigl|\widehat{(\boldsymbol{U}_0)}_k\bigr|^2
    |1-\Delta t\,\Lambda_k|^{2n}\|\Phi_k\|_{\boldsymbol{M}}^2.
\]
Since
\[
\|\boldsymbol{U}_0\|_{\boldsymbol{M}}^2
    =\sum_{k=1}^P\bigl|\widehat{(\boldsymbol{U}_0)}_k\bigr|^2
    \|\Phi_k\|_{\boldsymbol{M}}^2,
\]
it follows that
\[
\|\boldsymbol{U}^n\|_{\boldsymbol{M}}
    \le\Bigl(\max_{1\le k\le P}|1-\Delta t\,\Lambda_k|^n\Bigr)
    \|\boldsymbol{U}_0\|_{\boldsymbol{M}}
	=(|1-\Delta t\,\Lambda_P)^n\|\boldsymbol{U}_0\|_{\boldsymbol{M}}.
\]
Hence, if $\Delta t\le 1/\Lambda_P$ then $\|\boldsymbol{U}^n\|_{\boldsymbol{M}}
\le\|\boldsymbol{U}_0\|_{\boldsymbol{M}}$ and the forward Euler method is 
stable in the $\boldsymbol{M}$-norm.
\end{example}

\begin{example}
A similar argument shows that the backward Euler method gives
\[
\|\boldsymbol{U}^n\|_{\boldsymbol{M}}
    \le\Bigl(\max_{1\le k\le P}(1+\Delta t\,\Lambda_k)^{-n}\Bigr)
    \|\boldsymbol{U}_0\|_{\boldsymbol{M}}
	=(1+\Delta t\,\Lambda_1)^{-n}\|\boldsymbol{U}_0\|_{\boldsymbol{M}},
\]
and hence we have stability in the $\boldsymbol{M}$-norm for any~$\Delta t$.
\end{example}

\begin{example}
For the Crank--Nicolson method,
\[
\|\boldsymbol{U}^n\|_{\boldsymbol{M}}
    \le\biggl(\max_{1\le k\le P}\biggl|
    \frac{1-\tfrac12\Delta t\,\Lambda_k}{1+\tfrac12\Delta t\,\Lambda_k}
    \biggr|^n\biggr)\|\boldsymbol{U}_0\|_{\boldsymbol{M}}
=\biggl|\frac{1-\tfrac12\Delta t\,\Lambda_1}{1+\tfrac12\Delta t\,\Lambda_1}
	\biggr|^n\|\boldsymbol{U}_0\|_{\boldsymbol{M}},
\]
and we again have stability in the $\boldsymbol{M}$-norm for any~$\Delta t$.
\end{example}

\begin{Exercises}

\exercise\label{ex: quadratic form}
Suppose that $\boldsymbol{A}\in\mathbb{R}^{N\times N}$ is symmetric and 
positive-semidefinite, and let 
$\|\boldsymbol{v}\|=\sqrt{\boldsymbol{v}^T\boldsymbol{v}}$ denote the 
Euclidean norm in~$\boldsymbol{R}^N$.  
\begin{description}
\item{(i)}
Show that the minimum eigenvalue of~$\boldsymbol{A}$ equals the minimum value 
of the \emph{Rayleigh quotient}:
\[
\lambda_{\min}(\boldsymbol{A})
    =\min_{\boldsymbol{0}\ne\boldsymbol{v}\in\mathbb{R}^N}
    \frac{\boldsymbol{v}^T\boldsymbol{A}\boldsymbol{v}}{\|\boldsymbol{v}\|^2}.
\]
Hint: choose an orthonormal basis for~$\mathbb{R}^N$ consisting of eigenvectors 
of~$\boldsymbol{A}$.
\item{(ii)} Show likewise for the maximum eigenvalue that
\[
\lambda_{\max}(\boldsymbol{A})
    =\max_{\boldsymbol{0}\ne\boldsymbol{v}\in\mathbb{R}^N}
    \frac{\boldsymbol{v}^T\boldsymbol{A}\boldsymbol{v}}{\|\boldsymbol{v}\|^2}.
\]
\item{(iii)} How does this result generalise if we replace the Euclidean norm 
with the norm~$\|\boldsymbol{v}\|_{\boldsymbol{M}}=\sqrt{\boldsymbol{v}^T
\boldsymbol{M}\boldsymbol{v}}$ induced by a symmetric and strictly 
positive-definite matrix~$\boldsymbol{M}\in\mathbb{R}^{N\times N}$?
\end{description}

\exercise\label{ex: polynomial derivative}
Let $f(\xi)=a_1+a_2\xi+a_3\xi^2+\cdots+a_{r+1}\xi^r$ be any real polynomial of 
degree at most~$r$, and form the associated (column) vector of coefficients
$\boldsymbol{a}=[a_i]_{i=1}^{r+1}$.
\begin{description}
\item{(i)} Find the matrix~$\boldsymbol{B}$ such that 
$\int_0^1|f(\xi)|^2\,d\xi=\boldsymbol{a}^T\boldsymbol{B}\boldsymbol{a}$. 
\item{(ii)} Prove that $\boldsymbol{B}$ is symmetric and (strictly) 
positive-definite.
\item{(iii)} Find the matrix~$\boldsymbol{D}$ such that
$\int_0^1|f'(\xi)|^2\,d\xi=\boldsymbol{a}^T\boldsymbol{D}\boldsymbol{a}$. 
\item{(iv)} Prove that $\boldsymbol{D}$ is symmetric and positive-semidefinite.
\item{(v)} With the help of exercise~\ref{ex: quadratic form}, find a 
constant~$C_r$ (depending only on~$r$) such that
\[
\int_0^1|f'(\xi)|^2\,d\xi\le C_r\int_0^1|f(\xi)|^2\,d\xi.
\]
\item{(vi)} Compute the numerical value of $C_r$ for $r\in\{0,1,2,3\}$.
\end{description}
\begin{ans}
(i) $\boldsymbol{B}=[b_{ij}]_{i,j=1}^{r+1}$ where $b_{ij}=1/(i+j-1)$\quad
(iii) $\boldsymbol{D}=[d_{ij}]_{i,j=1}^{r+1}$ where 
\[
d_{ij}=\begin{cases}
    0&\text{if $i=1$ or $j=1$,}\\
    (i-1)(j-1)/(i+j-3)&\text{otherwise.}
\end{cases}
\]
(iv) $C_r=\lambda_{\max}(\boldsymbol{D})=\max_{\boldsymbol{a}\ne\boldsymbol{0}}
\boldsymbol{a}^T\boldsymbol{D}\boldsymbol{a}/
\boldsymbol{a}^T\boldsymbol{B}\boldsymbol{a}$ 
(vi)
\begin{center}
\renewcommand{\arraystretch}{1.25}
\begin{tabular}{r|r}
$r$&$C_r$\\
\hline
   0&     0.00\\
   1&    12.00\\
   2&    60.00\\
   3&   170.12
\end{tabular}
\end{center}
\end{ans}

\exercise
Let $C_r$ be the constant from part (v) of 
exercise~\ref{ex: polynomial derivative}, and recall the notation used in 
section~\ref{sec: accuracy of interpolation}.
\begin{description}
\item{(i)} Show that 
\[
\int_{x_{p-1}}^{x_p}|f(x)|^2\,dx=h_p\int_0^1|\hat f(\xi)|^2\,d\xi
\quad\text{and}\quad
\int_{x_{p-1}}^{x_p}|f'(x)|^2\,dx=h_p^{-1}\int_0^1|\hat f(\xi)|^2\,d\xi.
\]
\item{(ii)} Deduce that if $f\in\mathbb{P}_r$ then
\[
\int_{x_{p-1}}^{x_p}|f'(x)|^2\,dx
    \le C_rh_p^{-2}\int_{x_{p-1}}^{x_p}|f(x)|^2\,dx.
\]
\item{(iii)} Hence prove the \emph{inverse inequality}: if $v$ is a continuous 
piecewise polynomial of degree at most~$r$, then
\[
\int_0^L|v'(x)|^2\,dx\le C_rh_{\min}^{-2}\int_0^L|v(x)|^2\,dx
\quad\text{where $h_{\min}=\min_{1\le p\le P}h_p$.}
\]
\end{description}

\exercise
Recall the notation from sections 
\ref{sec: semidiscrete parabolic FEM}--\ref{sec: discrete separation}.
\begin{description}
\item{(i)}
Show that for any $v$, $w\in T_h$,
\[
\int_0^L\bigl(a(x)v'w'+c(x)vw\bigr)\,dx
    =\boldsymbol{V}^T(\boldsymbol{A}+\boldsymbol{C})\boldsymbol{W}
\quad\text{and}\quad
\int_0^Lv(x)^2=\boldsymbol{V}^T\boldsymbol{M}\boldsymbol{W},
\]
where $V_p=v(x_p)$~and $W_p=w(x_p)$.  
\item{(ii)}
Hence prove that
\[
\Lambda_P\le C_1h_{\min}^{-2}a_{\max}+c_{\max}\quad\text{where}\quad
a_{\max}=\max_{0\le x\le L}a(x)\quad\text{and}\quad
c_{\max}=\max_{0\le x\le L}c(x).
\]
\item{(iii)}
What does the upper bound in part~(ii) imply about the stability of the forward 
Euler method?
\end{description}
\begin{ans}
(iii) We saw in example~\ref{example: forward Euler FEM} that if $\Delta 
t>1/\Lambda_P$ then the forward Euler method has at least one unstable mode.  
Since $\Lambda_P=O(h_{\min}^{-2})$, to ensure stability we must expect to need 
$\Delta t$ of order~$h_{\min}^2$.  This conclusion is consistent with the 
stability condition of Theorem~\ref{thm: explicit Euler stability} for the 
finite difference case.
\end{ans}

\end{Exercises}



